{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55598df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pandas import value_counts\n",
    "import pickle\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from numpy import array, ndarray\n",
    "from pandas import read_csv, DataFrame, Series, concat\n",
    "from matplotlib.pyplot import figure, savefig, show, subplots\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.axes import Axes\n",
    "from scipy.stats import norm, expon, lognorm\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sys.path.insert(1, '../../../../utils')\n",
    "from dslabs_functions import get_variable_types, \\\n",
    "  CLASS_EVAL_METRICS, DELTA_IMPROVE, plot_bar_chart, plot_multiline_chart, plot_evaluation_results, \\\n",
    "  plot_horizontal_bar_chart, HEIGHT, plot_line_chart, dummify, run_NB, run_KNN, plot_multibar_chart, \\\n",
    "  encode_cyclic_variables, plot_confusion_matrix, NR_STDEV, determine_outlier_thresholds_for_var\n",
    "from studies import naive_Bayes_study, knn_study, evaluate_approach, evaluate_and_plot \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bc9463",
   "metadata": {},
   "source": [
    "### **Outliers** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccd95b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_tag = \"traffic\"\n",
    "lab_folder_out = \"lab3_preparation/outliers\"\n",
    "target_name = \"crash_type\"\n",
    "filename = \"../../data/prepared/traffic_enc1.csv\"\n",
    "# filename = \"../../data/prepared/traffic_enc2.csv\"\n",
    "data: DataFrame = read_csv(filename, na_values=\"\")\n",
    "variable_types: dict[str, list] = get_variable_types(data)\n",
    "# data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116f0e44",
   "metadata": {},
   "source": [
    "### Approach 1 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667e5343",
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_out1 = \"drop_outliers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403eb262",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_std: int = NR_STDEV\n",
    "numeric_vars: list[str] = get_variable_types(data)[\"numeric\"]\n",
    "if numeric_vars is not None:\n",
    "    df_out1: DataFrame = data.copy(deep=True)\n",
    "    summary5: DataFrame = data[numeric_vars].describe()\n",
    "    for var in numeric_vars:\n",
    "        top_threshold, bottom_threshold = determine_outlier_thresholds_for_var(\n",
    "            summary5[var]\n",
    "        )\n",
    "        outliers: Series = df_out1[(df_out1[var] > top_threshold) | (df_out1[var] < bottom_threshold)]\n",
    "        df_out1.drop(outliers.index, axis=0, inplace=True)\n",
    "    df_out1.to_csv(f\"../../data/prepared/{file_tag}_{approach_out1}.csv\", index=True)\n",
    "    print(f\"Data after dropping outliers: {df_out1.shape}\")\n",
    "else:\n",
    "    print(\"There are no numeric variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed766c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_plot(df_out1, lab_folder_out, file_tag, approach_out1, target_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294b000e",
   "metadata": {},
   "source": [
    "### Approach 2 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83aca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_out2 = \"replacing_outliers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3d9934",
   "metadata": {},
   "outputs": [],
   "source": [
    "if [] != numeric_vars:\n",
    "    df_out2: DataFrame = data.copy(deep=True)\n",
    "    for var in numeric_vars:\n",
    "        top, bottom = determine_outlier_thresholds_for_var(summary5[var])\n",
    "        median: float = df_out2[var].median()\n",
    "        df_out2[var] = df_out2[var].apply(lambda x: median if x > top or x < bottom else x)\n",
    "    df_out2.to_csv(f\"../../data/prepared/{file_tag}_{approach_out2}.csv\", index=True)\n",
    "    print(\"Data after replacing outliers:\", df_out2.shape)\n",
    "    print(df_out2.describe())\n",
    "else:\n",
    "    print(\"There are no numeric variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2531576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_plot(df_out2, lab_folder_out, file_tag, approach_out2, target_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662ebf90",
   "metadata": {},
   "source": [
    "### Approach 3 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce89248",
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_out3 = \"truncate_outliers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f8f574",
   "metadata": {},
   "outputs": [],
   "source": [
    "if [] != numeric_vars:\n",
    "    df_out3: DataFrame = data.copy(deep=True)\n",
    "    for var in numeric_vars:\n",
    "        top, bottom = determine_outlier_thresholds_for_var(summary5[var])\n",
    "        df_out3[var] = df_out3[var].apply(\n",
    "            lambda x: top if x > top else bottom if x < bottom else x\n",
    "        )\n",
    "    df_out3.to_csv(f\"../../data/prepared/{file_tag}_{approach_out3}.csv\", index=True)\n",
    "    print(\"Data after truncating outliers:\", df_out3.shape)\n",
    "    print(df_out3.describe())\n",
    "else:\n",
    "    print(\"There are no numeric variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7db2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_plot(df_out3, lab_folder_out, file_tag, approach_out3, target_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9a8ad1",
   "metadata": {},
   "source": [
    "### **Scaling** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfef0694",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_folder_sca = \"lab3_preparation/scaling\"\n",
    "\n",
    "# filename = \"../../data/prepared/traffic_outliers_drop_outliers.csv\"\n",
    "# filename = \"../../data/prepared/traffic_outliers_replacing_outliers.csv\"\n",
    "# filename = \"../../data/prepared/traffic_outliers_truncate_outliers.csv\"\n",
    "\n",
    "input_df = df_out3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dd691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_raw = \"../../data/raw/traffic_accidents.csv\"\n",
    "df_raw: DataFrame = read_csv(filename_raw, na_values=\"\")\n",
    "variable_types: dict[str, list] = get_variable_types(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dd30c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_vars = variable_types['numeric']\n",
    "df_raw[numeric_vars].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb441a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbolic_vars = variable_types['symbolic']\n",
    "df_raw[symbolic_vars].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b407901c",
   "metadata": {},
   "source": [
    "### Approach 1 - Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d560377",
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_sca1 = \"Standard-Scaler\"\n",
    "\n",
    "data_sca1 = input_df.copy()\n",
    "target: Series = data_sca1.pop(target_name)\n",
    "\n",
    "numeric_df = data_sca1[numeric_vars].copy()\n",
    "transf: StandardScaler = StandardScaler(with_mean=True, with_std=True, copy=True).fit(\n",
    "    numeric_df\n",
    ")\n",
    "numeric_df_scaled = DataFrame(transf.transform(numeric_df), index=data_sca1.index)\n",
    "data_sca1[numeric_vars] = numeric_df_scaled\n",
    "data_sca1[target_name] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17caead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_plot(data_sca1, lab_folder_sca, file_tag, approach_sca1, target_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea871567",
   "metadata": {},
   "source": [
    "### Approach 2 - MinMax Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae86cae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_sca2 = \"MinMax-Scaler\"\n",
    "\n",
    "data_sca2 = input_df.copy()\n",
    "target: Series = data_sca2.pop(target_name)\n",
    "\n",
    "numeric_df = data_sca2[numeric_vars].copy()\n",
    "transf: MinMaxScaler = MinMaxScaler(feature_range=(0, 1), copy=True).fit(numeric_df)\n",
    "numeric_df_scaled = DataFrame(transf.transform(numeric_df), index=data_sca2.index)\n",
    "data_sca2[numeric_vars] = numeric_df_scaled\n",
    "data_sca2[target_name] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012736ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_plot(data_sca2, lab_folder_sca, file_tag, approach_sca2, target_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3ef18b",
   "metadata": {},
   "source": [
    "### **Balancing** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6633c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_folder_bal = \"lab3_preparation/balancing\"\n",
    "\n",
    "# filename = \"../../data/prepared/traffic_outliers_drop_outliers.csv\"\n",
    "# filename = \"../../data/prepared/traffic_outliers_replacing_outliers.csv\"\n",
    "# filename = \"../../data/prepared/traffic_outliers_truncate_outliers.csv\"\n",
    "\n",
    "#input_df = data_sca1.copy()\n",
    "input_df = data_sca2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ac6861",
   "metadata": {},
   "source": [
    "### Approach 1 - Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0abf637",
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_bal1 = \"undersampling\"\n",
    "\n",
    "# Check class distribution before balancing\n",
    "print(\"Class distribution before undersampling:\")\n",
    "print(input_df[target_name].value_counts())\n",
    "print(f\"Ratio: {input_df[target_name].value_counts()[0] / input_df[target_name].value_counts()[1]:.2f}:1\")\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = input_df[input_df[target_name] == 0]\n",
    "df_minority = input_df[input_df[target_name] == 1]\n",
    "\n",
    "# Undersample majority class to match minority class size\n",
    "df_majority_undersampled = df_majority.sample(n=len(df_minority), random_state=42)\n",
    "\n",
    "# Combine minority class with undersampled majority class\n",
    "data_bal1 = concat([df_majority_undersampled, df_minority])\n",
    "\n",
    "# Shuffle the dataset\n",
    "data_bal1 = data_bal1.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nClass distribution after undersampling:\")\n",
    "print(data_bal1[target_name].value_counts())\n",
    "print(f\"Dataset size: {len(input_df)} → {len(data_bal1)} ({100*len(data_bal1)/len(input_df):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a713a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "evaluate_and_plot(data_bal1, lab_folder_bal, file_tag, approach_bal1, target_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8073844c",
   "metadata": {},
   "source": [
    "### Approach 2 - SMOTE (Synthetic Minority Over-sampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173050f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_bal2 = \"SMOTE\"\n",
    "\n",
    "# Check class distribution before balancing\n",
    "print(\"Class distribution before SMOTE:\")\n",
    "print(input_df[target_name].value_counts())\n",
    "\n",
    "# Separate features and target\n",
    "X = input_df.drop(columns=[target_name])\n",
    "y = input_df[target_name]\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Combine back into DataFrame\n",
    "data_bal2 = DataFrame(X_resampled, columns=X.columns)\n",
    "data_bal2[target_name] = y_resampled\n",
    "\n",
    "print(f\"\\nClass distribution after SMOTE:\")\n",
    "print(data_bal2[target_name].value_counts())\n",
    "print(f\"Dataset size: {len(input_df)} → {len(data_bal2)} ({100*len(data_bal2)/len(input_df):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa1b140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "evaluate_and_plot(data_bal2, lab_folder_bal, file_tag, approach_bal2, target_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
